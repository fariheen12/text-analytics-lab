{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "300b272d-1e4f-46e4-8471-7fd981e841af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab Assignment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "14f4f3c6-893d-416a-909b-a5dab8a7bbfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. MUHAMMAD FARIHEEN BIN ABD RAHIM (SW01082818)\\n2. MUHAMMAD ADEEB BIN ABDULLAH (SW01082814)\\n'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "1. MUHAMMAD FARIHEEN BIN ABD RAHIM (SW01082818)\n",
    "2. MUHAMMAD ADEEB BIN ABDULLAH (SW01082814)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "14553862-dd79-489a-ac8a-448d28124e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\anaconda\\lib\\site-packages (4.29.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\anaconda\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.2)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\anaconda\\lib\\site-packages (from selenium) (0.29.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\anaconda\\lib\\site-packages (from selenium) (0.12.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\anaconda\\lib\\site-packages (from selenium) (2024.8.30)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\anaconda\\lib\\site-packages (from selenium) (4.11.0)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\anaconda\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (25.3.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (3.7)\n",
      "Requirement already satisfied: outcome in c:\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.16.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\anaconda\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\anaconda\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\anaconda\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\anaconda\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1b5ede05-4c18-4dac-bffa-c2a8fedaa345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1...\n",
      "Reviewer Name: Chenta C.\n",
      "Review Date: 26 Dec 2024\n",
      "Review Content: ada kerosakan pd brg\n",
      "--------------------------------------------------------------------------------\n",
      "Reviewer Name: Nor A.\n",
      "Review Date: 08 Jun 2021\n",
      "Review Content: worth the money 游녨游녨游녨游녨游녨游녨游녨游녨游녨游녨游녨游녨 i like it, goood\n",
      "--------------------------------------------------------------------------------\n",
      "Reviewer Name: 1***4\n",
      "Review Date: 14 Apr 2023\n",
      "Review Content: Good seller. Everything ok and easy installation.\n",
      "--------------------------------------------------------------------------------\n",
      "Reviewer Name: Sehunnie\n",
      "Review Date: 31 Oct 2022\n",
      "Review Content: Very gooddd\n",
      "--------------------------------------------------------------------------------\n",
      "Reviewer Name: Agnes L.\n",
      "Review Date: 02 Jul 2021\n",
      "Review Content: The table top was slightly damaged as in the pictures. Also the table is a little wobbly, so don't put anything fragile on it. Super easy assembly.\n",
      "--------------------------------------------------------------------------------\n",
      "Scraping page 2...\n",
      "Reviewer Name: 0***7\n",
      "Review Date: 28 Sep 2021\n",
      "Review Content: ok.i love u..t.kasih..puning sikit nak pasang.apa2 pun t.kasih seller.terbaiiik游때游때游때游때游때游때游때游때\n",
      "--------------------------------------------------------------------------------\n",
      "Reviewer Name: nabilah N.\n",
      "Review Date: 17 Aug 2021\n",
      "Review Content: Kaki dia goyang2,ada satu kaki skru x leh masuk\n",
      "--------------------------------------------------------------------------------\n",
      "Reviewer Name: hanimhanan\n",
      "Review Date: 09 Oct 2022\n",
      "Review Content: pehantaran cepat \n",
      "--------------------------------------------------------------------------------\n",
      "Reviewer Name: chong K.\n",
      "Review Date: 08 Mar 2023\n",
      "Review Content: good product with fair price...fast delivery also\n",
      "--------------------------------------------------------------------------------\n",
      "Reviewer Name: KRull\n",
      "Review Date: 01 Oct 2022\n",
      "Review Content: perfect item rcv...worth the price\n",
      "--------------------------------------------------------------------------------\n",
      "Scraping page 3...\n",
      "Reviewer Name: Rita K.\n",
      "Review Date: 28 Oct 2021\n",
      "Review Content: Nice\n",
      "--------------------------------------------------------------------------------\n",
      "Reviewer Name: Collin L.\n",
      "Review Date: 20 Aug 2021\n",
      "Review Content: Great value for the price you pay, decent quality and easy to assemble.\n",
      "--------------------------------------------------------------------------------\n",
      "Reviewer Name: Shaiful N.\n",
      "Review Date: 15 Jul 2021\n",
      "Review Content: Reliable seller, fast delivery and  for the price kira OK la, goyang skit meja nie\n",
      "--------------------------------------------------------------------------------\n",
      "Reviewer Name: dzulkefli O.\n",
      "Review Date: 13 Aug 2021\n",
      "Review Content: 游녨游녨游녨游녨\n",
      "--------------------------------------------------------------------------------\n",
      "Reviewer Name: NORIZAN M.\n",
      "Review Date: 26 Feb 2023\n",
      "Review Content: kerusi dan meja cantik..cuma tersilap beli..patut beli besar sket..tp oklah... boleh letak brg jgk\n",
      "--------------------------------------------------------------------------------\n",
      "Scraping page 4...\n",
      "Reviewer Name: A***.\n",
      "Review Date: 13 Feb 2022\n",
      "Review Content: quality not good...table shaky eventho  fxed well...needs bracing \n",
      ".\n",
      "not happy bcos it will collapse or break any time .tabletop very thin ..pl dont buy this guys ...i regret for buying 2 pcs...\n",
      "--------------------------------------------------------------------------------\n",
      "Reviewer Name: S***a\n",
      "Review Date: 04 Dec 2022\n",
      "Review Content: Worth buying. Quality is good\n",
      "--------------------------------------------------------------------------------\n",
      "Reviewer Name: areel S.\n",
      "Review Date: 05 Aug 2021\n",
      "Review Content: please perform qc check before ship out.\n",
      "please improve on the wrapping.\n",
      "postage is fast.\n",
      "--------------------------------------------------------------------------------\n",
      "Reviewer Name: jayasheila\n",
      "Review Date: 23 Jul 2021\n",
      "Review Content: good\n",
      "--------------------------------------------------------------------------------\n",
      "Reviewer Name: 0***9\n",
      "Review Date: 03 Jun 2021\n",
      "Review Content: the chair seat is badly scratched. not sure whether happened during packaging or delivery. I am so upset. \n",
      "--------------------------------------------------------------------------------\n",
      "Scraping page 5...\n",
      "Reviewer Name: Norasyura\n",
      "Review Date: 24 Jun 2021\n",
      "Review Content: \n",
      "--------------------------------------------------------------------------------\n",
      "Reviewer Name: m***.\n",
      "Review Date: 29 Dec 2021\n",
      "Review Content: kualiti boleh2 saja...kaki meja bukan solid wood..cuma di balut plastik warna mcm kayu...\n",
      "--------------------------------------------------------------------------------\n",
      "Reviewer Name: C***.\n",
      "Review Date: 13 Sep 2021\n",
      "Review Content: Fast delivery. But bad quality-Wobbly legs & chipped at the side of the table.\n",
      "--------------------------------------------------------------------------------\n",
      "Scraping completed. Data saved to lazada_reviews.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import csv\n",
    "import time\n",
    "\n",
    "# Initialize the Chrome WebDriver\n",
    "driver_path = \"C:\\\\chromedriver.exe\"  # Path to the ChromeDriver executable\n",
    "service = Service(driver_path)  # Create a Service object using the ChromeDriver path\n",
    "driver = webdriver.Chrome(service=service)  # Initialize the Chrome WebDriver with the service\n",
    "\n",
    "# URL of the product page\n",
    "url = \"https://www.lazada.com.my/products/writing-table-home-office-desks-nordic-computer-modern-simple-study-table-meja-belajar-menulis-black-white-wood-i2040348294-s8108856141.html\"\n",
    "\n",
    "# Open the product page\n",
    "driver.get(url)  # Navigate to the specified URL in the browser\n",
    "\n",
    "# Wait for the page to load\n",
    "time.sleep(5)  # Pause the script for 5 seconds to allow the page to fully load\n",
    "\n",
    "# Function to extract review data\n",
    "def extract_reviews():\n",
    "    reviews = []  # Create an empty list to store review data\n",
    "    \n",
    "    # Find all review elements on the page using a CSS selector\n",
    "    review_elements = driver.find_elements(By.CSS_SELECTOR, '.mod-reviews .item')\n",
    "    \n",
    "    # Loop through each review element to extract details\n",
    "    for review in review_elements:\n",
    "        try:\n",
    "            # Extract reviewer name using a CSS selector\n",
    "            reviewer_name = review.find_element(By.CSS_SELECTOR, '.middle span').text\n",
    "        except:\n",
    "            reviewer_name = \"N/A\"  # If the reviewer name is not found, set it to \"N/A\"\n",
    "        \n",
    "        try:\n",
    "            # Extract review date using a CSS selector\n",
    "            review_date = review.find_element(By.CSS_SELECTOR, '.title.right').text\n",
    "        except:\n",
    "            review_date = \"N/A\"  # If the review date is not found, set it to \"N/A\"\n",
    "        \n",
    "        try:\n",
    "            # Extract review content using a CSS selector\n",
    "            review_content = review.find_element(By.CSS_SELECTOR, '.content').text\n",
    "        except:\n",
    "            review_content = \"N/A\"  # If the review content is not found, set it to \"N/A\"\n",
    "        \n",
    "        # Append the extracted review data as a dictionary to the reviews list\n",
    "        reviews.append({\n",
    "            'Reviewer Name': reviewer_name,\n",
    "            'Review Date': review_date,\n",
    "            'Review Content': review_content\n",
    "        })\n",
    "    \n",
    "    return reviews  # Return the list of reviews\n",
    "\n",
    "# Function to save reviews to CSV\n",
    "def save_to_csv(reviews, filename='lazada_reviews.csv'):\n",
    "    keys = reviews[0].keys()  # Get the keys (column names) from the first review dictionary\n",
    "    \n",
    "    # Open the CSV file for writing with UTF-8 encoding\n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as output_file:\n",
    "        dict_writer = csv.DictWriter(output_file, fieldnames=keys)  # Create a DictWriter object\n",
    "        dict_writer.writeheader()  # Write the header row (column names) to the CSV\n",
    "        dict_writer.writerows(reviews)  # Write all the review data to the CSV\n",
    "\n",
    "# Main scraping logic\n",
    "all_reviews = []  # Create an empty list to store all reviews from multiple pages\n",
    "\n",
    "# Scrape reviews from 5 pages\n",
    "for page in range(5):\n",
    "    print(f\"Scraping page {page + 1}...\")  # Print the current page number being scraped\n",
    "    reviews = extract_reviews()  # Extract reviews from the current page\n",
    "    all_reviews.extend(reviews)  # Add the extracted reviews to the all_reviews list\n",
    "    \n",
    "    # Display the scraped reviews in the console\n",
    "    for review in reviews:\n",
    "        print(f\"Reviewer Name: {review['Reviewer Name']}\")  # Print reviewer name\n",
    "        print(f\"Review Date: {review['Review Date']}\")  # Print review date\n",
    "        print(f\"Review Content: {review['Review Content']}\")  # Print review content\n",
    "        print('-' * 80)  # Print a separator line\n",
    "    \n",
    "    # Click the next page button if available\n",
    "    try:\n",
    "        # Find the \"next page\" button using a CSS selector\n",
    "        next_button = driver.find_element(By.CSS_SELECTOR, '.next-pagination-item.next')\n",
    "        \n",
    "        # Check if the \"next page\" button is disabled (no more pages)\n",
    "        if 'disabled' in next_button.get_attribute('class'):\n",
    "            break  # Exit the loop if there are no more pages\n",
    "        \n",
    "        next_button.click()  # Click the \"next page\" button\n",
    "        time.sleep(5)  # Wait for 5 seconds to allow the next page to load\n",
    "    except:\n",
    "        break  # Exit the loop if an error occurs (e.g., no \"next page\" button found)\n",
    "\n",
    "# Save all reviews to CSV\n",
    "save_to_csv(all_reviews)  # Save all the scraped reviews to a CSV file\n",
    "print(\"Scraping completed. Data saved to lazada_reviews.csv\")  # Print a completion message\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()  # Close the Chrome browser and end the WebDriver session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d00a98-0109-4cc2-a940-474b8240b0b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
